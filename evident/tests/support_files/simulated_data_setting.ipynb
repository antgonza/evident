{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook is to generate the simulated data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simulated mapping files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general mapping file: 120 subjects with 20 missing values \n",
    "# age -- continous variable; \n",
    "# gender -- categorical variable with 2 levels; \n",
    "# country -- categorical variable with 4 levels\n",
    "\n",
    "np.random.seed(31)\n",
    "mapping = pd.DataFrame(\n",
    "    {'#SampleID': ['10000.000001010' +\n",
    "                   x for x in np.char.mod(\n",
    "                       '%d', np.arange(start=1, stop=121, step=1))],\n",
    "     'Age': np.append(np.sort(np.round(np.random.normal(loc=40, scale=5,\n",
    "                      size=100), decimals=0)), np.repeat('nan', 20)),\n",
    "     'Gender': np.append(np.repeat(np.array(['Male', 'Female']), 50),\n",
    "                         np.repeat('Not applicable', 20)),\n",
    "     'Country': np.append(np.repeat(np.array(['US', 'France',\n",
    "                                              'Germany', 'Mexico']), 25),\n",
    "                          np.repeat('Missing: Not provided', 20))})\n",
    "mapping.set_index('#SampleID', inplace=True)\n",
    "\n",
    "# separate mapping files\n",
    "# age\n",
    "mapping_age = pd.DataFrame({'#SampleID': ['10000.000001010' +\n",
    "                            x for x in np.char.mod(\n",
    "                              '%d', np.arange(start=1, stop=121, step=1))],\n",
    "                            'Age': mapping.Age})\n",
    "mapping_age.set_index('#SampleID', inplace=True)\n",
    "\n",
    "# gender\n",
    "mapping_gender = pd.DataFrame({'#SampleID': ['10000.000001010' +\n",
    "                              x for x in np.char.mod(\n",
    "                                '%d', np.arange(start=1, stop=121, step=1))],\n",
    "                              'Gender': mapping.Gender})\n",
    "mapping_gender.set_index('#SampleID', inplace=True)\n",
    "\n",
    "# country\n",
    "mapping_country = pd.DataFrame({'#SampleID': ['10000.000001010' +\n",
    "                               x for x in np.char.mod(\n",
    "                                 '%d', np.arange(start=1, stop=121, step=1))],\n",
    "                               'Country': mapping.Country})\n",
    "mapping_country.set_index('#SampleID', inplace=True)\n",
    "\n",
    "mapping.to_csv('mappings.txt', sep='\\t')\n",
    "mapping_age.to_csv('mapping_age.txt', sep='\\t')\n",
    "mapping_gender.to_csv('mapping_gender.txt', sep='\\t')\n",
    "mapping_country.to_csv('mapping_country.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simulated alpha diversities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multipe alphas:\n",
    "# Faith_PD ~ Uniform (0, 40): negligible effect size\n",
    "# Shannon: a mixture of N(100, 1) and N(3, 1): largest effect size\n",
    "# Observed_OTUs: a mixture of N(5, 2), N(15, 10), N(20, 8) and N(30, 2): medium effect size\n",
    "# Expected effect size (from smallest to biggest): Faith_PD < Observed_OTUs < Shannon\n",
    "# Expected p-value (from smallest to biggest): Shannon < Observed_OTUs < Faith_PD\n",
    "\n",
    "alpha_div = pd.DataFrame({'#SampleID': ['10000.000001010' +\n",
    "                         x for x in np.char.mod(\n",
    "                           '%d', np.arange(start=1, stop=121, step=1))],\n",
    "                          'Faith_PD': np.append(np.random.uniform(\n",
    "                            low=0, high=40, size=100),\n",
    "                            np.repeat('None', 20)),\n",
    "                          'Shannon': np.concatenate(\n",
    "                            (abs(np.random.normal(loc=100, scale=1, size=60)),\n",
    "                             abs(np.random.normal(loc=3, scale=1, size=60)))),\n",
    "                          'Observed_OTUs': np.concatenate(\n",
    "                            (abs(np.random.normal(loc=5, scale=2, size=30)),\n",
    "                             abs(np.random.normal(loc=15, scale=10, size=30)),\n",
    "                             abs(np.random.normal(loc=20, scale=8, size=30)),\n",
    "                             abs(np.random.normal(\n",
    "                                loc=30, scale=2, size=30))))})\n",
    "alpha_div.set_index('#SampleID', inplace=True)\n",
    "\n",
    "# separate alpha diversity file\n",
    "# Faith_PD\n",
    "alpha_pd = pd.DataFrame({'#SampleID': ['10000.000001010' +\n",
    "                        x for x in np.char.mod(\n",
    "                          '%d', np.arange(start=1, stop=121, step=1))],\n",
    "                         'Faith_PD': alpha_div.Faith_PD})\n",
    "alpha_pd.set_index('#SampleID', inplace=True)\n",
    "\n",
    "# Shannon\n",
    "alpha_sn = pd.DataFrame({'#SampleID': ['10000.000001010' +\n",
    "                        x for x in np.char.mod(\n",
    "                          '%d', np.arange(start=1, stop=121, step=1))],\n",
    "                         'Shannon': alpha_div.Shannon})\n",
    "alpha_sn.set_index('#SampleID', inplace=True)\n",
    "\n",
    "# Observed_OTUs\n",
    "alpha_otu = pd.DataFrame({'#SampleID': ['10000.000001010' +\n",
    "                         x for x in np.char.mod(\n",
    "                           '%d', np.arange(start=1, stop=121, step=1))],\n",
    "                         'Observed_OTUs': alpha_div.Observed_OTUs})\n",
    "alpha_otu.set_index('#SampleID', inplace=True)\n",
    "\n",
    "# output alpha diversity files\n",
    "alpha_div.to_csv('alphas.txt', sep='\\t')\n",
    "alpha_pd.to_csv('alpha_pd.txt', sep='\\t')\n",
    "alpha_sn.to_csv('alpha_sn.txt', sep='\\t')\n",
    "alpha_otu.to_csv('alpha_otu.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
